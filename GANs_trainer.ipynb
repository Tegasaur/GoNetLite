{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python380jvsc74a57bd0ce0c727c0923861906b0fd7103761b05c39ba96d05f0b864509d71ba978b2080",
   "display_name": "Python 3.8.0 64-bit ('tf2.4': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_yaml\n",
    "import keras.layers\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from skimage import color, io\n",
    "from skimage.transform import resize\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input data from set of images\n",
    "X_train_g = np.zeros((80000, 32, 32, 3), dtype = \"float\")\n",
    "index = 0\n",
    "\n",
    "#--------------------------------------------------------\n",
    "# Pass path for positive gan image folder below\n",
    "for filepath in glob.iglob('data_train/positive_L/*'):\n",
    "# Pass path for positive gan image folder above\n",
    "#--------------------------------------------------------\n",
    "\n",
    "    image = resize(io.imread(filepath), (32, 32))\n",
    "    X_train_g[index] = np.array(image).reshape(32, 32, 3) \n",
    "    index += 1\n",
    "    if index == 79999:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for training discriminator\n",
    "def sample_for_d(X_train_g, sample_size, generator):\n",
    "    # Generated Images\n",
    "    random_input = np.random.normal(0, 1, size = (sample_size, 100))\n",
    "    X1 = generator(random_input)\n",
    "    Y1 = np.zeros((sample_size, 1))\n",
    "\n",
    "    # Real Images\n",
    "    index = np.random.randint(79999, size = (sample_size))\n",
    "    X2 = X_train_g[index]\n",
    "    Y2 = np.ones((sample_size, 1))\n",
    "\n",
    "    return [X1, Y1, X2, Y2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for training generator\n",
    "def sample_for_g(X_train_g, sample_size):\n",
    "    X = np.random.normal(0, 1, size = (sample_size, 100))\n",
    "    Y = np.ones((sample_size,1))\n",
    "\n",
    "    return [X, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function for training inverse generator\n",
    "def sample_for_ig(X_train_g, sample_size, generator):\n",
    "    X = np.zeros((sample_size, 32, 32, 3))\n",
    "    Y = np.zeros((sample_size, 32, 32, 3))\n",
    "    for i in range(0,sample_size):\n",
    "        count = np.random.randint(79999)\n",
    "        X[i] = X_train_g[count]\n",
    "        Y[i] = X_train_g[count]\n",
    "\n",
    "    return [X, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to save images and monitor training\n",
    "def save_imgs(epoch):\n",
    "    r, c = 2, 2\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/gan_1_%d.png\" % epoch)\n",
    "    plt.close()\n",
    "\n",
    "def save_imgs2(epoch, image):\n",
    "    r, c = 2, 2\n",
    "    noise = invGenerator(image.reshape([1,32,32,3]))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if i == 0:\n",
    "                axs[i,j].imshow(gen_imgs[cnt])\n",
    "                axs[i,j].axis('off')\n",
    "            else:\n",
    "                axs[i,j].imshow(image, cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "    fig.savefig(\"images/gan_2_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inverse Generative Model\n",
    "img_shape = (32,32,3)\n",
    "input_shape = (100,)\n",
    "invGenerator = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same', input_shape = img_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(256, (4,4), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(100)\n",
    "])\n",
    "invGenerator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generative Model\n",
    "img_shape = (32,32,3)\n",
    "input_shape = (100,)\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.Dense(4 * 4 * 256, input_shape = input_shape),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Reshape((4, 4, 256)),\n",
    "    keras.layers.Conv2DTranspose(256, (4,4), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(3, (3,3), activation='relu', padding='same')\n",
    "])\n",
    "generator.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminative Model\n",
    "layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Conv2D(256, (3,3), strides=(2,2), padding='same'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.4),\n",
    "    keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation of first level gan (Training for first constraint)\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5), metrics=[\"accuracy\"])\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "discriminator.trainable = False\n",
    "gan1 = keras.models.Sequential([generator, discriminator])\n",
    "gan1.compile(loss =\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5), metrics=[\"accuracy\"])\n",
    "gan1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Procedure\n",
    "for i in range(100000):\n",
    "\n",
    "    discriminator.trainable = True\n",
    "    [X_batch_d, Y_batch_d, X_batch_d2, Y_batch_d2] = sample_for_d(X_train_g, 32, generator)\n",
    "    loss1 = discriminator.train_on_batch(X_batch_d, Y_batch_d)\n",
    "    loss2 = discriminator.train_on_batch(X_batch_d2, Y_batch_d2)\n",
    "    # print(f\"{(loss1[1] + loss2[1])/ 2}\")\n",
    "\n",
    "    discriminator.trainable = False\n",
    "    [X_batch_g, Y_batch_g] = sample_for_g(X_train_g, 64)\n",
    "    loss = gan1.train_on_batch(X_batch_g, Y_batch_g)\n",
    "    # print(loss[0])\n",
    "\n",
    "    print(i)\n",
    "    if i%1000 == 0:\n",
    "        save_imgs(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compilation of second level gan (Training for second constraint)\n",
    "generator.trainable = False\n",
    "gan2 = keras.models.Sequential([invGenerator, generator])\n",
    "gan2.compile(loss = \"mean_squared_error\", optimizer = Adam(0.0003, 0.5))\n",
    "gan2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Procedure\n",
    "print(\"Inverse Generator\")\n",
    "loss = gan2.fit(X_train_g, X_train_g, epochs = 10, batch_size = 100)\n",
    "save_imgs2(0, X_train_g[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save gan2 as encoder\n",
    "model_yaml = gan2.to_yaml()\n",
    "with open(\"encoder.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "gan2.save_weights(\"encoder.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ]
}